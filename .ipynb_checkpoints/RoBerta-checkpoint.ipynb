{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c711ebf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d68a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/tweets.csv')\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4bf15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns\n",
    "df.set_axis(['tweet', 'directed', 'emotion'], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ad091c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TweetEval preprocess function\n",
    "\n",
    "def preprocess(text):\n",
    "    new_text = []\n",
    "    for t in text.split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f695554d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7fc565",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import csv\n",
    "import urllib.request\n",
    "\n",
    "task='sentiment'\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-{task}\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1417e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4e3307",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452a9d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download label mapping\n",
    "mapping_link = f\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/{task}/mapping.txt\"\n",
    "with urllib.request.urlopen(mapping_link) as f:\n",
    "    html = f.read().decode('utf-8').split(\"\\n\")\n",
    "    csvreader = csv.reader(html, delimiter='\\t')\n",
    "labels = [row[1] for row in csvreader if len(row) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef42542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PT\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL, from_tf=True)\n",
    "\n",
    "text = \"Good night ðŸ˜Š\"\n",
    "text = preprocess(text)\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)\n",
    "scores = output[0][0].detach().numpy()\n",
    "scores = softmax(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840046cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking = np.argsort(scores)\n",
    "ranking = ranking[::-1]\n",
    "for i in range(scores.shape[0]):\n",
    "    l = labels[ranking[i]]\n",
    "    s = scores[ranking[i]]\n",
    "    print(f\"{i+1}) {l} {np.round(float(s), 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09531c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_roberta(df):\n",
    "    clean_tweets = []\n",
    "    for tweet in df['tweet']:\n",
    "        words = str(tweet).split()\n",
    "        new_text = []\n",
    "        for t in words:\n",
    "            t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "            t = '@user' if t.startswith('.@') and len(t) > 1 else t\n",
    "            t = 'http' if t.startswith('http') else t\n",
    "            new_text.append(t)\n",
    "        new_t = \" \".join(new_text)\n",
    "        clean_tweets.append(new_t)\n",
    "    df['clean_tweet'] = clean_tweets\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ac4771",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_roberta = clean_roberta(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64430487",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_roberta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba31ddd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoded_input_df = clean_roberta['clean_tweet'].apply(tokenizer.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0a8aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoded_input_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dc7bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output = model(**encoded_input_df)\n",
    "#scores = output[0][0].detach().numpy()\n",
    "#scores = softmax(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326e5bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = clean_roberta['clean_tweet'][5]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461642c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing model\n",
    "\n",
    "encoded_input_test = tokenizer(test, return_tensors='pt')\n",
    "encoded_input_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9248624",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing model\n",
    "output_test = model(**encoded_input_test)\n",
    "output_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef8c76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing model\n",
    "scores_test = output_test[0][0].detach().numpy()\n",
    "scores_test = softmax(scores_test)\n",
    "scores_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefcbfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing model\n",
    "ranking_test = np.argsort(scores_test)\n",
    "ranking_test = ranking_test[::-1]\n",
    "for i in range(scores_test.shape[0]):\n",
    "    l = labels[ranking_test[i]]\n",
    "    s = scores_test[ranking_test[i]]\n",
    "    print(f\"{i+1}) {l} {np.round(float(s), 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f4bdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = clean_roberta['clean_tweet'][0]\n",
    "encoded_input_test2 = tokenizer(test2, return_tensors='pt')\n",
    "output_test2 = model(**encoded_input_test2)\n",
    "scores_test2 = output_test2[0][0].detach().numpy()\n",
    "scores_test2 = softmax(scores_test2)\n",
    "ranking_test2 = np.argsort(scores_test2)\n",
    "ranking_test2 = ranking_test2[::-1]\n",
    "for i in range(scores_test2.shape[0]):\n",
    "    l = labels[ranking_test2[i]]\n",
    "    s = scores_test2[ranking_test2[i]]\n",
    "    print(f\"{i+1}) {l} {np.round(float(s), 4)}\")\n",
    "print(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9250c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "test3 = clean_roberta['clean_tweet'][5]\n",
    "encoded_input_test3 = tokenizer(test3, return_tensors='pt')\n",
    "output_test3 = model(**encoded_input_test3)\n",
    "scores_test3 = output_test3[0][0].detach().numpy()\n",
    "scores_test3 = softmax(scores_test3)\n",
    "ranking_test3 = np.argsort(scores_test3)\n",
    "ranking_test3 = ranking_test3[::-1]\n",
    "for i in range(scores_test3.shape[0]):\n",
    "    l = labels[ranking_test3[i]]\n",
    "    s = scores_test3[ranking_test3[i]]\n",
    "    print(f\"{i+1}) {l} {np.round(float(s), 4)}\")\n",
    "print(test3)b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d123b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_test3 = softmax(scores_test3)\n",
    "score_list = []\n",
    "neg = scores_test3[0]\n",
    "score_list.append(neg)\n",
    "neut = scores_test3[1]\n",
    "score_list.append(neut)\n",
    "pos = scores_test3[2]\n",
    "score_list.append(pos)\n",
    "\n",
    "for score in score_list:\n",
    "    if max(score_list) == neg:\n",
    "        score = 0\n",
    "    elif max(score_list) == neut:\n",
    "        score = 1\n",
    "    elif max(score_list) == pos:\n",
    "        score = 2\n",
    "print(test3)\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4fda71",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_roberta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e216f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_roberta(df):\n",
    "    sentiment = []\n",
    "    \n",
    "    #encode and run through model in clean_tweets\n",
    "    for tweet in df['tweet']:\n",
    "        encoded_input = tokenizer(str(tweet), return_tensors='pt')\n",
    "        output = model(**encoded_input)\n",
    "        scores = output[0][0].detach().numpy()\n",
    "        scores = softmax(scores)\n",
    "        \n",
    "\n",
    "        score_list = []\n",
    "        neg = scores_test3[0]\n",
    "        score_list.append(neg)\n",
    "        neut = scores_test3[1]\n",
    "        score_list.append(neut)\n",
    "        pos = scores_test3[2]\n",
    "        score_list.append(pos)\n",
    "\n",
    "        for score in score_list:\n",
    "            if max(score_list) == neg:\n",
    "                score = 0\n",
    "            elif max(score_list) == neut:\n",
    "                score = 1\n",
    "            elif max(score_list) == pos:\n",
    "                score = 2\n",
    "        sentiment.append(score)\n",
    "        \n",
    "    clean_roberta['score'] = sentiment\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c97ef7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
